{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f865661",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c7145c",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b8a7ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "#from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "from detoxify import Detoxify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "62c6c5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('C:/project/project13/toxic_comments.csv', on_bad_lines='skip')\n",
    "except:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56496b00",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8f3cc1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.info()\n",
    "#data.toxic.unique()\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59414621",
   "metadata": {},
   "source": [
    "### С данными все в порядке: Целевой признак в числовом формате, уникальные значения 0 и 1. Необходимо только удалить столбец 'Unnamed: 0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8feefab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd93fc9",
   "metadata": {},
   "source": [
    "## Проведем предобработку данных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d55c65",
   "metadata": {},
   "source": [
    "### Выделим некоторые признаки из текста, которые могут иметь значение. Тут следует отметить, что оригинальная задача решалась на кейсе на определение авторства текстов. В нашем случае есть смысл отдельно посчитать восклицательные знаки и символы, которые используют для закрытия части нецензурных слов ($#*%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "da349b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>processed</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>words_not_stopword</th>\n",
       "      <th>exclamation</th>\n",
       "      <th>simbols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>248</td>\n",
       "      <td>43</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww he matches this background colour i'm se...</td>\n",
       "      <td>88</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i'm really not trying to edit war it's...</td>\n",
       "      <td>229</td>\n",
       "      <td>42</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "\n",
       "                                           processed  length  words  \\\n",
       "0  explanation why the edits made under my userna...     248     43   \n",
       "1  d'aww he matches this background colour i'm se...      88     14   \n",
       "2  hey man i'm really not trying to edit war it's...     229     42   \n",
       "\n",
       "   words_not_stopword  exclamation  simbols  \n",
       "0                  24            0        0  \n",
       "1                  11            1        0  \n",
       "2                  22            0        0  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "#напишем функцию, которая будет извлекать признаки из текста\n",
    "# https://www.kaggle.com/code/gooogr/a-deep-dive-into-sklearn-pipelines-forked/notebook\n",
    "def processing(df):\n",
    "    #приведение к нижнему регистру и удаление пунктуации\n",
    "    df['processed'] = df['text'].apply(lambda x: \" \".join(re.sub(r\"[^a-zA-Z']\", \" \", x.lower()).split())) \n",
    "    #длина предложения (символов) \n",
    "    df['length'] = df['processed'].apply(lambda x: len(x))\n",
    "    #количество слов\n",
    "    df['words'] = df['processed'].apply(lambda x: len(x.split(' ')))\n",
    "    #количество слов, за исключением stopwords - слов, не несущих смысловой накрузки\n",
    "    df['words_not_stopword'] = df['processed'].apply(lambda x: len([t for t in x.split(' ') if t not in stopWords]))\n",
    "    #считаем восклицательные знаки Exclamation point\n",
    "    df['exclamation'] = df['text'].apply(lambda x: x.count('!'))\n",
    "    #Why Do We Use Symbols To Censor Swearwords\n",
    "    df['simbols'] = df['text'].apply(lambda x: x.count('$')+x.count('#')+x.count('*')+x.count('%')) #$#*%\n",
    "\n",
    "    return(df)\n",
    "\n",
    "data = processing(data)\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b00b0860",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy() #для эксперимента с модулем Detoxify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23941702",
   "metadata": {},
   "source": [
    "### Лемматизируем текст в колонке 'processed', удалим уже ненужную колонку 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0d5caca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15min 8s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>processed</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>words_not_stopword</th>\n",
       "      <th>exclamation</th>\n",
       "      <th>simbols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "      <td>248</td>\n",
       "      <td>43</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>d'aww he match this background colour i 'm see...</td>\n",
       "      <td>88</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>hey man i 'm really not try to edit war it 's ...</td>\n",
       "      <td>229</td>\n",
       "      <td>42</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic                                          processed  length  words  \\\n",
       "0      0  explanation why the edits make under my userna...     248     43   \n",
       "1      0  d'aww he match this background colour i 'm see...      88     14   \n",
       "2      0  hey man i 'm really not try to edit war it 's ...     229     42   \n",
       "\n",
       "   words_not_stopword  exclamation  simbols  \n",
       "0                  24            0        0  \n",
       "1                  11            1        0  \n",
       "2                  22            0        0  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Функция возвращает тэг типа слова в wordnet (nltk.pos_tag выдает какие-то свои типы)\n",
    "def pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:         \n",
    "        return None\n",
    "\n",
    "def lemmatize(text): # в функцию подается ощищенный текст, на выходе получаем лемматизированный текст по \n",
    "#всем типам слов (lemmatizer + POS)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # tokenize the sentence and find the POS tag for each token\n",
    "    pos_tagged = nltk.pos_tag(nltk.word_tokenize(text))   \n",
    "    # As you may have noticed, the above pos tags are a little confusing.\n",
    "    # we use our own pos_tagger function to make things simpler to understand.\n",
    "    wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tagged))\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            # if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:       \n",
    "            # else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    lemmatized_sentence = \" \".join(lemmatized_sentence)\n",
    "    return lemmatized_sentence\n",
    "\n",
    "data['processed'] = data.processed.apply(lemmatize)\n",
    "data = data.drop(columns='text')\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaf05a6",
   "metadata": {},
   "source": [
    "### Как мы видим, признаки в нашем датасете неоднородны. Числовые хорошо бы отмаштабировать, а на основе текста создать векторы Tfid. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac04925",
   "metadata": {},
   "source": [
    "### Разобьем выборки на тренировочную, валидационную и тестовую. Валидационную выборку можно было бы не выделять (сделать кросс-валидацию), но на ней надо будет подобрать оптимальный порог для лучшего F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "620cc762",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data, test_size=0.2, random_state=12345)\n",
    "data_train, data_val = train_test_split(data_train, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffd2b37",
   "metadata": {},
   "source": [
    "### Сама схема для Pipeline следующая: \n",
    "1. Преобразуем текстовое поле\n",
    "2. Преобразуем числовые поля\n",
    "3. Объединим преобразованные поля в один датасет\n",
    "4. На тренировочной выборке определим оптимальные параметры через кросс-валидацию, максимизируя Auc-Roc\n",
    "5. На тренировочной и валидационных выборках определим порог для максимального F1 для этих параметров\n",
    "6. Проверим нашу модель на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c167df17",
   "metadata": {},
   "source": [
    "### Для того, чтобы выбрать нужные поля для преобразования в рамках Pipeline, необходимо создать свой собственный класс, который будет возвращать колонку с заданным типом данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f8eed376",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator, TransformerMixin): #судя по всему, класс наследует опеределенные параметры\n",
    "    # и методы от классов BaseEstimator, TransformerMixin, которые позволяют использовать его в Pipeline\n",
    "    \"\"\"\n",
    "     Transformer to select a part of the data frame to perform additional transformations on\n",
    "     \"\"\"\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bdde5764",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_feature = 'processed'\n",
    "num_features_list = ['length', 'words', 'words_not_stopword', 'exclamation', 'simbols']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce63187b",
   "metadata": {},
   "source": [
    "### Векторизируем текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "08a425c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<95574x114641 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2204859 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = Pipeline([\n",
    "                ('selector', DataFrameSelector(str_feature)),\n",
    "                ('tfidf', TfidfVectorizer(stop_words='english'))\n",
    "            ])\n",
    "\n",
    "text.fit_transform(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc9b7ae",
   "metadata": {},
   "source": [
    "### Масштабируем числовые признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c25b5924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.19478033, -0.21112447, -0.16722706, -0.0255081 , -0.10662224],\n",
       "       [ 0.22583871,  0.25118041,  0.1828991 , -0.0255081 , -0.10662224],\n",
       "       [-0.47103437, -0.48247734, -0.46207013, -0.0255081 , -0.10662224],\n",
       "       ...,\n",
       "       [ 0.19375759,  0.16072946,  0.25660987, -0.0255081 , -0.10662224],\n",
       "       [-0.5904474 , -0.59302851, -0.59106398, -0.0255081 , -0.10662224],\n",
       "       [-0.38013788, -0.40207649, -0.36993167, -0.0255081 , -0.10662224]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_feats = Pipeline([\n",
    "    ('selector', DataFrameSelector(num_features_list)),\n",
    "    ('standard', StandardScaler())\n",
    "])\n",
    "\n",
    "num_feats.fit_transform(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1864e52b",
   "metadata": {},
   "source": [
    "### Объединяем в один датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "648a92ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<95574x114646 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2682729 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The feature union itself is not a pipeline, it's just a union, so you need to do one more step to make it useable: \n",
    "#pass it to a pipeline, with the same structure, an array of tuples, with the simple (name, object) format\n",
    "\n",
    "feats = FeatureUnion([\n",
    "    ('text', text),\n",
    "    ('num_feats', num_feats)\n",
    "])\n",
    "\n",
    "feature_processing = Pipeline([('feats', feats)])\n",
    "feature_processing.fit_transform(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81910d97",
   "metadata": {},
   "source": [
    "## Подберем оптимальную модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a4b186",
   "metadata": {},
   "source": [
    "### Подберем параметры для логической регрессии, которая традиционно дает хорошие результаты для текстов.\n",
    "Выбор модели основан на этой статье https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f36689",
   "metadata": {},
   "source": [
    "#### Добавим в Pipeline логическую регрессию и выведем доступные для настройки параметры для всего пайплайна."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "79cac713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'features', 'lgr', 'features__n_jobs', 'features__transformer_list', 'features__transformer_weights', 'features__verbose', 'features__text', 'features__num_feats', 'features__text__memory', 'features__text__steps', 'features__text__verbose', 'features__text__selector', 'features__text__tfidf', 'features__text__selector__attribute_names', 'features__text__tfidf__analyzer', 'features__text__tfidf__binary', 'features__text__tfidf__decode_error', 'features__text__tfidf__dtype', 'features__text__tfidf__encoding', 'features__text__tfidf__input', 'features__text__tfidf__lowercase', 'features__text__tfidf__max_df', 'features__text__tfidf__max_features', 'features__text__tfidf__min_df', 'features__text__tfidf__ngram_range', 'features__text__tfidf__norm', 'features__text__tfidf__preprocessor', 'features__text__tfidf__smooth_idf', 'features__text__tfidf__stop_words', 'features__text__tfidf__strip_accents', 'features__text__tfidf__sublinear_tf', 'features__text__tfidf__token_pattern', 'features__text__tfidf__tokenizer', 'features__text__tfidf__use_idf', 'features__text__tfidf__vocabulary', 'features__num_feats__memory', 'features__num_feats__steps', 'features__num_feats__verbose', 'features__num_feats__selector', 'features__num_feats__standard', 'features__num_feats__selector__attribute_names', 'features__num_feats__standard__copy', 'features__num_feats__standard__with_mean', 'features__num_feats__standard__with_std', 'lgr__C', 'lgr__class_weight', 'lgr__dual', 'lgr__fit_intercept', 'lgr__intercept_scaling', 'lgr__l1_ratio', 'lgr__max_iter', 'lgr__multi_class', 'lgr__n_jobs', 'lgr__penalty', 'lgr__random_state', 'lgr__solver', 'lgr__tol', 'lgr__verbose', 'lgr__warm_start'])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipeline = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('lgr', LogisticRegression(max_iter=1000)), # задал max_iter здесь, т.к. на дефолтных 100 выдает ошибку\n",
    "])\n",
    "\n",
    "pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d79083",
   "metadata": {},
   "source": [
    "#### Выберем самые интересные параметры для перебора и определим те, которые максимизируют 'roc_auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "40f643b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'features__text__tfidf__max_features': None,\n",
       " 'features__text__tfidf__ngram_range': (1, 2),\n",
       " 'lgr__C': 10,\n",
       " 'lgr__class_weight': None}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "hyperparameters = { 'features__text__tfidf__max_features': [1000, None],\n",
    "                    'features__text__tfidf__ngram_range': [(1,1), (1,2)],\n",
    "                    'lgr__class_weight': [None, 'balanced'],\n",
    "                    'lgr__C': [0.1, 1, 10]\n",
    "                  }\n",
    "clf = GridSearchCV(pipeline, hyperparameters, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    " \n",
    "# Fit and tune model\n",
    "clf.fit(data_train, data_train['toxic'])\n",
    "clf.best_params_\n",
    "\n",
    "#Wall time: 30min 41s\n",
    "#{'features__text__tfidf__max_features': None,\n",
    "# 'features__text__tfidf__ngram_range': (1, 2),\n",
    "# 'lgr__C': 10,\n",
    "# 'lgr__class_weight': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f72510be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#refitting on entire training data using best settings\n",
    "clf.refit\n",
    "probabilities_valid = clf.predict_proba(data_val)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2d8b61ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7749523204068658 0.28\n"
     ]
    }
   ],
   "source": [
    "f1_max = 0\n",
    "threshold_opt = None\n",
    "\n",
    "for threshold in np.arange(0, 1, 0.02):\n",
    "    predicted_valid = probabilities_one_valid > threshold \n",
    "    f1 = f1_score(predicted_valid, data_val['toxic'])\n",
    "    if f1>f1_max:\n",
    "        f1_max=f1\n",
    "        threshold_opt = threshold\n",
    "        \n",
    "print (f1_max, threshold_opt) \n",
    "# 0.7749523204068658 0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "df0c6e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7889471176750834"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities_test = clf.predict_proba(data_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "predicted_test = probabilities_one_test > 0.28\n",
    "f1_score(predicted_test, data_test['toxic'])\n",
    "#0.7889471176750834"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1220f6",
   "metadata": {},
   "source": [
    "#### Логическая регрессия показала на тестовой выборке F1 0.79 (на валидационной 0.775) при пороге 0.28 и следующих параметрах:\n",
    "1. TfidfVectorizer: max_features: None, ngram_range: (1, 2)\n",
    "2. LogisticRegression(max_iter=1000): C: 10, class_weight: None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99ebbb1",
   "metadata": {},
   "source": [
    "### Сравним достигнутый показатель качества с предсказаниями на основе модуля Detoxify (toxic Bert). \n",
    "Модуль на входе получает ощищенный текст, назад возвращает некоторые оценки токсичности, основанные на 7 параметрах: 'toxicity', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat', 'sexual_explicit'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bffcf6",
   "metadata": {},
   "source": [
    "#### Сократим размер датасета до 10000 записей, к сожалению, полный будет обрабатываться значительное время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f69b34cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/unitaryai/detoxify\n",
    "# GPU https://www.kaggle.com/code/sorenj/scoring-comments-using-unitaryai-detoxify/notebook\n",
    "df = df.sample(10000, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "814342ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Detoxify('unbiased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e3fdcaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_features(x):\n",
    "    prediction = predictor.predict(x['processed'])\n",
    "    return prediction['toxicity'], prediction['severe_toxicity'], prediction['obscene'], prediction['identity_attack'], prediction['insult'], prediction['threat'], prediction['sexual_explicit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "95748b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 55min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_features = df.apply(new_features, axis=1, result_type='expand')\n",
    "df_features.columns = ['toxicity', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat', 'sexual_explicit']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7c04f0",
   "metadata": {},
   "source": [
    "#### После преобразования столбца с текстом, у нас получился следующий датасет с признаками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c750c56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>sexual_explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109486</th>\n",
       "      <td>0.002178</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104980</th>\n",
       "      <td>0.128936</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.009342</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.027453</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.019332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82166</th>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        toxicity  severe_toxicity   obscene  identity_attack    insult  \\\n",
       "109486  0.002178         0.000002  0.000042         0.000863  0.000376   \n",
       "104980  0.128936         0.000047  0.009342         0.000694  0.027453   \n",
       "82166   0.000613         0.000002  0.000034         0.000080  0.000107   \n",
       "\n",
       "          threat  sexual_explicit  \n",
       "109486  0.000038         0.000020  \n",
       "104980  0.000345         0.019332  \n",
       "82166   0.000029         0.000022  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091651f3",
   "metadata": {},
   "source": [
    "#### Разобьем выборку на тренировочную, валидационную и тестовую, подберем оптимальные параметры логической регрессии, максимизируем F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "118d1fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_train, df_features_test, df_target_train, df_target_test = train_test_split(df_features, df['toxic'], test_size=0.2, random_state=12345)\n",
    "df_features_train, df_features_val, df_target_train, df_target_val = train_test_split(df_features_train, df_target_train, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "0972ffb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'class_weight': 'balanced'}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "hyperparameters = {\n",
    "                    'class_weight': [None, 'balanced'],\n",
    "                    'C': [0.1, 1, 10]\n",
    "                  }\n",
    "\n",
    "clf = GridSearchCV(model, param_grid = hyperparameters, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    " \n",
    "# Fit and tune model\n",
    "clf.fit(df_features_train, df_target_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "417da057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#refitting on entire training data using best settings\n",
    "clf.refit\n",
    "probabilities_valid = clf.predict_proba(df_features_val)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "550f6b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8534704370179949 0.8200000000000001\n"
     ]
    }
   ],
   "source": [
    "f1_max = 0\n",
    "threshold_opt = None\n",
    "\n",
    "for threshold in np.arange(0, 1, 0.02):\n",
    "    predicted_valid = probabilities_one_valid > threshold \n",
    "    f1 = f1_score(predicted_valid, df_target_val)\n",
    "    if f1>f1_max:\n",
    "        f1_max=f1\n",
    "        threshold_opt = threshold\n",
    "        \n",
    "print (f1_max, threshold_opt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0bdc5d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7607573149741824"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities_test = clf.predict_proba(df_features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "predicted_test = probabilities_one_test > 0.2\n",
    "f1_score(predicted_test, df_target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76c1dee",
   "metadata": {},
   "source": [
    "#### На валидационной выборке удалось достичь учень хорошего уровня F1: 0.85. При этом, показатели на тестовой выборке существенно ухудшились, всего 0.76. Полагаю, что это связано с недостаточностью выборки, и по полным данным можно выйти на F1 0.84- 0.85."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4f9d55",
   "metadata": {},
   "source": [
    "# Выводы\n",
    "1. Нам удалось постоить модель с параметрами F1 на тестовой выборке, превышающими 0.75 (0.79(0.775 - валидация)).\n",
    "2. Модуль Detoxify потенциально показывает существенно больший F1 (до 0.85), но требует обработки датасета на существенно бОльших мощностях. При обработке всего датасета с GPU на Google Colab, модель достигла F1 0.884 на тестовой выборке (0.917 на валидационной)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
